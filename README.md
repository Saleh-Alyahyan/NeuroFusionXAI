# NeuroFusionXAI

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

**A Privacy-Preserving Cross-Modality Explainable Fusion Framework for Early Neurodegenerative Disease Detection**

## ğŸ“‹ Overview

NeuroFusionXAI is a novel privacy-preserving cross-modality explainable fusion framework designed for early neurodegenerative disease detection. The framework integrates multimodal neuroimaging data (structural MRI, functional MRI, and PET scans) through a sophisticated fusion architecture that employs federated learning principles to ensure data privacy.

### Key Features

- **Cross-Modality Fusion**: Vision Transformers and Graph Neural Networks for enhanced feature extraction from multimodal neuroimaging data
- **Privacy Preservation**: Homomorphic encryption (CKKS scheme) and differential privacy mechanisms
- **Explainable AI**: Integrated LIME, SHAP, and Grad-CAM for clinically interpretable insights
- **Federated Learning**: Domain-shift-aware federated aggregation for multi-institutional collaboration

### Performance

| Disease | Accuracy | Sensitivity | Specificity | F1-Score |
|---------|----------|-------------|-------------|----------|
| Alzheimer's Disease | 94.7% | 93.2% | 95.8% | 94.5% |
| Parkinson's Disease | 92.3% | 91.1% | 93.4% | 91.8% |
| MCI Detection | 91.3% | 89.7% | 92.1% | 90.4% |

## ğŸ—‚ï¸ Repository Structure

```
NeuroFusionXAI/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml                    # Main configuration file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vision_transformer.py      # 3D Vision Transformer for neuroimaging
â”‚   â”‚   â”œâ”€â”€ graph_neural_network.py    # GNN for brain connectivity
â”‚   â”‚   â”œâ”€â”€ cross_attention_fusion.py  # Cross-modality fusion module
â”‚   â”‚   â””â”€â”€ neurofusionxai.py          # Main NeuroFusionXAI model
â”‚   â”œâ”€â”€ privacy/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ differential_privacy.py    # DP mechanisms
â”‚   â”‚   â”œâ”€â”€ homomorphic_encryption.py  # CKKS encryption
â”‚   â”‚   â””â”€â”€ federated_learning.py      # Federated learning with secure aggregation
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lime_explainer.py          # LIME explanations
â”‚   â”‚   â”œâ”€â”€ shap_explainer.py          # SHAP values
â”‚   â”‚   â””â”€â”€ gradcam.py                 # Grad-CAM visualizations
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py                 # Dataset classes
â”‚   â”‚   â””â”€â”€ preprocessing.py           # Data preprocessing utilities
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ metrics.py                 # Evaluation metrics
â”‚       â””â”€â”€ visualization.py           # Visualization utilities
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.py                       # Training script
â”‚   â”œâ”€â”€ evaluate.py                    # Evaluation script
â”‚   â””â”€â”€ inference.py                   # Inference script
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_models.py                 # Unit tests
â””â”€â”€ docs/
    â””â”€â”€ METHODOLOGY.md                 # Detailed methodology
```

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- CUDA 11.0+ (for GPU support)
- 16GB+ GPU memory recommended

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/NeuroFusionXAI.git
cd NeuroFusionXAI

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install package in development mode
pip install -e .
```

## ğŸ“Š Datasets

### ADNI (Alzheimer's Disease Neuroimaging Initiative)
- **Access**: https://adni.loni.usc.edu/data-samples/adni-data/
- **Subjects**: 2,847 participants
- **Modalities**: sMRI, fMRI, PET
- **Registration Required**: Yes (free for researchers)

### PPMI (Parkinson's Progression Markers Initiative)
- **Access**: https://www.ppmi-info.org/access-data-specimens/download-data/
- **Alternative**: https://www.kaggle.com/datasets/vikasukani/parkinsons-disease-data-set
- **Subjects**: 1,423 participants
- **Modalities**: sMRI, fMRI, DaTscan

### Data Preparation

After downloading the datasets, organize them as follows:

```
data/
â”œâ”€â”€ ADNI/
â”‚   â”œâ”€â”€ sMRI/
â”‚   â”œâ”€â”€ fMRI/
â”‚   â””â”€â”€ PET/
â”œâ”€â”€ PPMI/
â”‚   â”œâ”€â”€ sMRI/
â”‚   â”œâ”€â”€ fMRI/
â”‚   â””â”€â”€ DaTscan/
â””â”€â”€ labels/
    â”œâ”€â”€ adni_labels.csv
    â””â”€â”€ ppmi_labels.csv
```

## ğŸš€ Quick Start

### Training

```bash
# Single-site training
python scripts/train.py --config configs/config.yaml --dataset ADNI

# Federated learning across multiple sites
python scripts/train.py --config configs/config.yaml --federated --num_sites 5
```

### Evaluation

```bash
python scripts/evaluate.py --checkpoint checkpoints/best_model.pt --dataset ADNI
```

### Inference with Explainability

```bash
python scripts/inference.py --checkpoint checkpoints/best_model.pt \
    --input_smri patient_smri.nii.gz \
    --input_fmri patient_fmri.nii.gz \
    --input_pet patient_pet.nii.gz \
    --explain
```

## ğŸ”§ Configuration

Key configuration parameters in `configs/config.yaml`:

```yaml
model:
  vit_patch_size: [16, 16, 16]
  vit_embed_dim: 768
  vit_num_heads: 12
  vit_num_layers: 12
  fusion_layers: 8
  fusion_heads: 16

privacy:
  epsilon: 0.5
  delta: 1e-5
  noise_multiplier: 1.1
  max_grad_norm: 1.0

training:
  batch_size: 16
  learning_rate: 1e-4
  epochs: 120
  optimizer: adamw
  weight_decay: 0.01
```

## ğŸ“ˆ Results Reproduction

To reproduce the results from the paper:

```bash
# Run full experiment pipeline
python scripts/train.py --config configs/config.yaml \
    --dataset ADNI \
    --federated \
    --num_sites 5 \
    --privacy_budget 0.5 \
    --cross_validation 5
```

## ğŸ”¬ Model Architecture

### Vision Transformer (ViT)
- **Patch Size**: 16Ã—16Ã—16 volumetric patches
- **Embedding Dimension**: 768
- **Transformer Blocks**: 12
- **Attention Heads**: 12

### Cross-Attention Fusion
- **Fusion Layers**: 8
- **Attention Heads**: 16
- **Hidden Dimension**: 1024

### Graph Neural Network
- **Architecture**: 3-layer Graph Attention Network (GAT)
- **Hidden Dimensions**: 256 â†’ 128 â†’ 64
- **Brain Regions**: Based on AAL atlas (116 regions)

### Privacy Mechanisms
- **Differential Privacy**: (Îµ=0.5, Î´=10â»âµ)
- **Encryption**: CKKS homomorphic encryption
- **Federated Aggregation**: Domain-shift-aware FedAvg

## ğŸ“ Citation

If you use this code in your research, please cite:

```bibtex
@article{neurofusionxai2025,
  title={NeuroFusionXAI: A Privacy-Preserving Cross-Modality Explainable Fusion Framework for Early Neurodegenerative Disease Detection},
  author={[Authors]},
  journal={[Journal]},
  year={2025}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines and submit pull requests.

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact [author email].

## ğŸ™ Acknowledgments

- ADNI and PPMI consortiums for providing the neuroimaging datasets
- The open-source community for the foundational libraries

---

**Disclaimer**: This framework is for research purposes only. Clinical use requires appropriate regulatory approval.
